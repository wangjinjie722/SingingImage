{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不停弹出TF框架 那就手动依次执行代码 等待转圈结束再执行下一个 这样的话检测几率会小一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  原百度AI项目地址（B站id:xiaoxu12315）：[点我](https://aistudio.baidu.com/aistudio/projectdetail/745434)\n",
    "\n",
    ">Github作者:[我](https://github.com/AliaksandrSiarohin/first-order-model)还有[我](https://github.com/dunnousername/yanderifier)\n",
    "\n",
    ">  B站教程：[点我](https://www.bilibili.com/video/BV1Mv41117LV)\n",
    "\n",
    "> 此版本为匹配B站视频教学，基于xiaoxu代码修改，对使用有疑问请加QQ群：776823471"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为减少高峰期，在不使用的时候务必到项目首页点击停止**\n",
    "\n",
    "**嘛...搞出来自己玩玩或者给朋友发就行了...还是不要传到b站为好**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QQ群：776823471 提供更多口型素材 并负责手把手教学 入群免费代做一次**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1a8186bc7a864faf84084ed222615a11b637be72f9fd4a6b90b7b3e785a3f59a)\n",
    "**部分素材效果演示：**[点我](http://www.bilibili.com/video/BV1z54y127fB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**在file文件夹内放素材,将视频更改为import.mp4,图片更改为import.png 视频和图片分辨率:256x256 \n",
    "\n",
    "有时候刷不出file文件夹，自己新建一个就可以了，新建按钮在上传按钮的左边，第二次做，只需要删除要换的素材后上传新的就可以了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **最佳效果方案：**\n",
    "\n",
    "尽量只保留脖子到头发的部分，其他地方不留；图片人物脸的角度参照视频母体的人物角度，建议使用真人，非三次元人类做出来效果会怪怪的\n",
    "\n",
    "**例如：unravel母体的最佳图片是证件照的标准。**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5f486a61622145c49968c07ae2f2c366909f544f105e46aabcb112d6c7c750e9)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0986c2b958ce44439592d952276ad4ced9362c201d1840ceb6dbd91a69df9597)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a84dc5dafd314ed2ac657df4bf7d7881deef718b468c4f8f83c645c16a097e69)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b6e3aad4214f4d71a153e079c4729d37e6693230fc334879ba603e130442943b)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/07d6e2bd8c1146e5b421d43d24b400671e1cdd092c704239b874fe1ac031af17)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/746437a626754f07bc6012e7b58d758d1f59af5e5e0c4f6088530d3cd205a8bc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用过程中遇到以下提示,重启项目便可**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8e2c76e9c4274c3ba34b266e0d1f0f9fe6c13581515c4b5b9cbc491caa4c4d4e)\n",
    "\n",
    "若不小心误动代码，请重置项目：[点我](https://aistudio.baidu.com/aistudio/projectdetail/986206) 进去后重新运行一次即可\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/aistudio/data': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#查看数据集\n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/aistudio/work': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "sys.path.append('/home/aistudio/first-order-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'first-order-model' already exists and is not an empty directory.\n",
      "/bin/sh: 1: cd: can't cd to /home/aistudio/first-order-model\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/kai/anaconda3/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: scikit-image in /home/kai/anaconda3/lib/python3.7/site-packages (0.16.2)\n",
      "Requirement already satisfied: torch==1.0.0 in /home/kai/anaconda3/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: torchvision==0.2.1 in /home/kai/anaconda3/lib/python3.7/site-packages (0.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (3.1.3)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: six in /home/kai/anaconda3/lib/python3.7/site-packages (from torchvision==0.2.1) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/kai/anaconda3/lib/python3.7/site-packages (from torchvision==0.2.1) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kai/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/kai/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/kai/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kai/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/kai/anaconda3/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: setuptools in /home/kai/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://gitee.com/xiaoxu12315/first-order-model.git\n",
    "#从码云克隆仓库\n",
    "!cd /home/aistudio/first-order-model\n",
    "#进入工作目录\n",
    "#如果这一步出错可以更换其他源 https://blog.csdn.net/sinat_21591675/article/details/82770360\n",
    "#红色报错代码：ERROR: visualdl 2.0.0b8 has requirement Pillow>=7.0.0, but you'll have pillow 5.2.0 which is incompatible. 可以无视 不影响程序执行\n",
    "#!pip install -i https://mirrors.aliyun.com/pypi/simple/ moviepy cffi==1.11.5 cloudpickle==1.2.1 cycler==0.10.0 dask==0.18.2 decorator==4.3.0 imageio==2.5.0 kiwisolver==1.0.1 matplotlib==2.2.2 networkx==2.1 numpy==1.15.0 pandas==0.23.4 Pillow==5.2.0 pycparser==2.18 pygit==0.1 pyparsing==2.2.0 python-dateutil==2.7.3 pytz==2018.5 PyWavelets==0.5.2 PyYAML==5.1 scikit-image==0.14.0 scikit-learn==0.19.2 scipy==1.1.0 six==1.14.0 toolz==0.9.0 torch==1.0.0 torchvision==0.2.1 tqdm==4.24.0\n",
    "!pip install -i https://mirrors.aliyun.com/pypi/simple/ imageio-ffmpeg scikit-image torch==1.0.0 torchvision==0.2.1\n",
    "#安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /home/kai/anaconda3/lib/python3.7/site-packages (1.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Requested MovieWriter (ffmpeg) not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86b8515f4805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriving_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mto_html5_video\u001b[0;34m(self, embed_limit)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;31m# We create a writer manually so that we can get the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;31m# appropriate size for the tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m                 \u001b[0mWriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.writer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m                 writer = Writer(codec='h264',\n\u001b[1;32m   1328\u001b[0m                                 \u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.bitrate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise RuntimeError(\n\u001b[0;32m--> 164\u001b[0;31m                 'Requested MovieWriter ({}) not available'.format(name))\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requested MovieWriter (ffmpeg) not available"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/local/bin/ffmpeg'\n",
    "\n",
    "source_image = imageio.imread('file/import.png')\n",
    "driving_video = imageio.mimread('file/import.mp4',memtest=False)\n",
    "\n",
    "\n",
    "#调整图片和视频分辨率\n",
    "\n",
    "source_image = resize(source_image, (256, 256))[..., :3]\n",
    "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "\n",
    "def display(source, driving, generated=None):\n",
    "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
    "    ims = []\n",
    "    for i in range(len(driving)):\n",
    "        cols = [source]\n",
    "        cols.append(driving[i])\n",
    "        if generated is not None:\n",
    "            cols.append(generated[i])\n",
    "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
    "        plt.axis('off')\n",
    "        ims.append([im])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani\n",
    "    \n",
    "\n",
    "HTML(display(source_image, driving_video).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'demo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8f17c36c447e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdemo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m generator, kp_detector = load_checkpoints(config_path='first-order-model/config/vox-256.yaml', \n\u001b[1;32m      3\u001b[0m                             checkpoint_path='data/data51886/checkpoint.tar')\n\u001b[1;32m      4\u001b[0m                             \u001b[0;31m#加载配置文件并加载数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'demo'"
     ]
    }
   ],
   "source": [
    "from demo import load_checkpoints\n",
    "generator, kp_detector = load_checkpoints(config_path='first-order-model/config/vox-256.yaml', \n",
    "                            checkpoint_path='data/data51886/checkpoint.tar')\n",
    "                            #加载配置文件并加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'demo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5b71e56b4667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdemo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_as_ubyte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriving_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'demo'"
     ]
    }
   ],
   "source": [
    "from demo import make_animation\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
    "\n",
    "#保存结果\n",
    "imageio.mimsave('work/result 1.mp4', [img_as_ubyte(frame) for frame in predictions])\n",
    "\n",
    "HTML(display(source_image, driving_video, predictions).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import VideoWriter,VideoWriter_fourcc\n",
    "\n",
    "video_root =\"file/import.mp4\"\n",
    "cap = cv2.VideoCapture(video_root)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "resize_width = 256\n",
    "resize_height = 256\n",
    "double_fps = 2*fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import VideoWriter,VideoWriter_fourcc\n",
    "\n",
    "video_root =\"work/result 1.mp4\"\n",
    "out_root = \"work/result 2.mp4\"\n",
    "cap = cv2.VideoCapture(video_root)\n",
    "resize_width = 256\n",
    "resize_height = 256\n",
    "double_fps = 2*fps\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "videoWriter = cv2.VideoWriter(out_root,fourcc,fps,(256,256))\n",
    "\n",
    "success = cap.isOpened()\n",
    "while (success):\n",
    "    success,frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    frame = cv2.resize(frame,(256,256))\n",
    "    videoWriter.write(frame)\n",
    "videoWriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b7103bb6e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 读取2个视频文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvideoclip_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file/import.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvideoclip_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"work/result 2.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "# 读取2个视频文件 \n",
    "videoclip_1 = VideoFileClip(\"file/import.mp4\")\n",
    "videoclip_2 = VideoFileClip(\"work/result 2.mp4\")\n",
    "\n",
    "# 提取第一个视频文件的音频部分\n",
    "audio_1 = videoclip_1.audio\n",
    "\n",
    "# 将提取的音频和第二个视频文件进行合成\n",
    "videoclip_3 = videoclip_2.set_audio(audio_1)\n",
    "# 输出新的视频文件\n",
    "videoclip_3.write_videofile(\"file/export.mp4\", audio_codec=\"aac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2541267cbea94a4882f7c5baacc40e5fd13384954996462fa6f6feb510d6b01e)\n",
    "<center><font size=\"10\" >许可证:<a target=\"_blank\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\">CC-BY-NC v4.0</a></font></center>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
